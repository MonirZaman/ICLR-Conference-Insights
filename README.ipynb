{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI research showcased at \n",
    "# International Conference on Learning Representations (ICLR) 2018\n",
    "\n",
    "[Conference proceedings and open review](https://openreview.net/group?id=ICLR.cc/2018/Conference)\n",
    "\n",
    "### Summary\n",
    "\n",
    "#### Generative adversarial network (GAN)\n",
    "* Common usecase: generate photo realistic images e.g., road pictures at different lighting\n",
    "* Research problems\n",
    "    * Mode collapse: \n",
    "    * Zero-shot learning\n",
    "\n",
    "#### Reinforcement learning\n",
    "* Common usecase: \n",
    "    * Training of machine learning model using real-time feedback \n",
    "    * E.g., AlphaGo\n",
    "* Research problems\n",
    "    * Policy gradient\n",
    "    \n",
    "#### Graph-based Neural Network\n",
    "* Common usecase: \n",
    "    * Find bugs in software code repositories\n",
    "\n",
    "#### Sequence model: MACnets\n",
    "* Common usecase: \n",
    "    * Language translation, Question and answer\n",
    "* Research problems\n",
    "    * Reasoning\n",
    "    * E.g., What is name of the building that is by the eight ave, left to Holt Renfrew and next to Banker's hall? Eighth avenue place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keynote 1: What Can Machine Learning Do? Workforce Implications\n",
    "Erik Brynjolfsson  \n",
    "MIT  \n",
    "\n",
    "[URL](https://openreview.net/forum?id=B1QRgziT-)\n",
    "\n",
    "* Economist's perspective of AI \n",
    "    * Average person's life did not much until 1775 (Steam engine)\n",
    "    * Steam engine is a general purose technology\n",
    "\n",
    "    * AI is a general purpose technology\n",
    "        * Pervasive\n",
    "        * Improve over time\n",
    "        * Complementary innovation  \n",
    "    \n",
    "** \"Our job is to solve intelligence and then use that to solve problems of the world\", Demis Hassabis, DeepMind**\n",
    "\n",
    "* Backlash against technology\n",
    "* Challenges\n",
    "    * Income distribution\n",
    "    * Job loss\n",
    "    * False news\n",
    "    * Bias\n",
    "    \n",
    "** There is no shortage of work that only humans can do **\n",
    "\n",
    "* Additional considerations:  \n",
    "    * No economic law that most people will benefit\n",
    "    * Median family income remains flat\n",
    "    * Corporate profit does not distribute to labours\n",
    "    * There are more millionairs and billionairs (1%)\n",
    "\n",
    "* Suitable for Machine learning (SML) tasks\n",
    "    * Experiment to detemine which tasks are suitable for machines\n",
    "    * Machine learning is not good at developing treatment plans as done by Radiologists\n",
    "    * SML score is not correlated with Wage\n",
    "    \n",
    "* To Dos:  \n",
    "    * Design parameters/policies \n",
    "    * Reinvent future of work\n",
    "    * Invent technology to augment human instead of replacing human\n",
    "    * Techonology does not decide how income distribution is done; humans do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keynote 2: Augmenting Clinical Intellgence with Machine Intelligence  \n",
    "Suchi Saria  \n",
    "John Hopkins University  \n",
    "\n",
    "* Machine learning can improve accuracy of clinical decisions\n",
    "* Diverse data source\n",
    "    * Discrete Events Laboratories\n",
    "    * Continuous physiologic measurements\n",
    "\n",
    "* Computational diagnostics for Parkinsons\n",
    "    * Determine the right dose of medication\n",
    "    * Objectively quantify patients condition\n",
    "    * Developed Android app to use cell phone sensors\n",
    "    \n",
    "    * Machine learning: Input are the cell phone's sensor's data \n",
    "      and output is the severity of the disease\n",
    "    * Max margin comparision between before medication and after medication test\n",
    "    * Semi-supervised learning to learn cheaply\n",
    "\n",
    "* Early diagnosis and prevention\n",
    "    * Forecasting the risk of a patient to be hospitalized in the short term future\n",
    "    * Analyze Sparse and irregular time series\n",
    "    * Segment time series - Sliding window approach\n",
    "        * Supervised learning \n",
    "        * Policy changes \n",
    "        * Control the changes in the future (NIPS paper) \n",
    "        * Incorporate counter factor and confounder\n",
    "        * Control regime where something might changes between sliding window and the risk assessment period.        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive Growing of GANs for Improved Quality, Stability, and Variation\n",
    "Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen  \n",
    "NVIDIA  \n",
    "\n",
    "* Training GAN\n",
    "    * GAN for high resolution\n",
    "    * Start with small resolution\n",
    "    * As we are close to goal, increase the resolution\n",
    "![image](image/progressive-gan.png)\n",
    "    * Resemble multilayer auto-encoder training \n",
    "* Normalization \n",
    "    * D - nothing\n",
    "    * G - Pixel normalization\n",
    "    \n",
    "* Dataset - LSUN\n",
    "* Sliced Wasserstein distance is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein auto-encoders (WAE)\n",
    "Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly and Bernhard Schoelkopf  \n",
    "[URL](https://iclr.cc/Conferences/2018/Schedule?showEvent=369)\n",
    "\n",
    "* Generative adversarial networks (GANs) (Goodfellow et al., 2014) have been very popular to generate high quality images\n",
    "    * However, GAN comes without an auto-encoder as it is desirable to reconstruct the latent codes and use the learned manifold\n",
    "    * GAN is harder to train \n",
    "    * GAN suffers from the \"mode collapses\" where the resulting model is unable to capture all the variability in the true data distribution\n",
    "\n",
    "* Variational auto-encoder (VAE), on the other hand, contains a good theoretical foundation for a generative model while providing a learned representation of the input\n",
    "    * However, VAE does not generate good quality images\n",
    "    \n",
    "* Wasserstein auto-encoder (WAE) blends the adversarial training of GANs with autoencoder architectures\n",
    "* WAE approach generative modeling from the optimal transport (OT) point of view. The OT cost (Villani, 2003) is a way to measure a distance between probability distributions\n",
    "* Objective of WAE has two terms: \n",
    "    1. Reconstruction cost\n",
    "        * It ensures that latent codes provided to the decoder are informative enough to reconstruct the encoded training examples\n",
    "    1. Regularizer $D_{Z}(P_{Z};Q_{Z})$ \n",
    "        * It penalizes a discrepancy between two distributions in $Z$ and $P_{Z}$ and a distribution of encoded data points, i.e. $Q_{Z} := E_{P_{X}}[Q(Z|X)]$\n",
    "        * It captures how distinct the image by the encoder of each training example is from the prior $P_{Z}$\n",
    "\n",
    "![image](image\\wae-overview.png)\n",
    "\n",
    "* Two different regularizers have been proposed\n",
    "    * WAE-GAN: is based on GANs and adversarial training in the latent space Z. \n",
    "    * WAE-MMD: uses the maximum mean discrepancy which is known to perform well when matching high-dimensional standard normal distributions $P_{Z}$ (Gretton et al., 2012).\n",
    "\n",
    "![image](image\\wae-gan-output-mnist.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPP-NET:  PLATFORM-AWARE PROGRESSIVE SEARCH FOR PARETO-OPTIMAL NEURAL ARCHITECTURES \n",
    "Jin-Dong Dong, An-Chieh Cheng, Da-Cheng Juan, Wei Wei& Min Sun\n",
    "\n",
    "Proposal:  \n",
    "* Find out optimal Neural network architecture using Pareto optimization\n",
    "* Optimization objectives - accuracy and computational cost\n",
    "    \n",
    "Methodology:  \n",
    "* Start with best know network configurations - DenseNet, SparseNet\n",
    "\n",
    "* Mutate: Add layers from the search space\n",
    "![image](image/search-space.png)\n",
    "* RNN Regressor\n",
    "    * Input: architecture and previous layer's accuracy\n",
    "    * Infer network's true accuracy given its architechture\n",
    "* Select K networks using Pareto Optimality\n",
    "![image](image/architecture-selection-pipeline.png)\n",
    "\n",
    "* Update regressor\n",
    "     * Train the selected K networks each for N epochs\n",
    "     * Use the evaluation accuracies (output) and the architectures (inputs) to update the RNN regressor\n",
    "\n",
    "* Performance of each layer is feed to a RNN Regressor as well as each model settings is fed to the regressor as embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to represent program using Graphs\n",
    "Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi  \n",
    "Microsoft Research  \n",
    "\n",
    "Proposal  \n",
    "* Graphs to represent both syntactic and semantic structure of code\n",
    "* Apply Deep Neural Network to reason over the graph \n",
    "* Applications  \n",
    "    * Variable Misuse identifying\n",
    "    * Generate proper variable names  \n",
    "    * Find bug  \n",
    "    \n",
    "* Learning to Reason about Code\n",
    "    * Control flow\n",
    "        * Last use, write and computed from\n",
    "    * Data flow\n",
    "\n",
    "* Graph Neural Network\n",
    "![image](image/program-graph.png)\n",
    "    * Based on Gate Graph Neural Networks\n",
    "    * Program graph uses Abstract Syntax Tree (AST)\n",
    "    * Additional edges are added to capture control and data flow\n",
    "    * Use word embedding for tokens\n",
    "![image](image/GNN-output.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MASKGAN: BETTER TEXT GENERATION VIA FILLING IN THE ______\n",
    "William Fedus, Ian Goodfellow and Andrew M. Dai  \n",
    "Google Brain  \n",
    "\n",
    "* Propose to use Generative Adversarial Network to fill missing text in a paragraph\n",
    "* Current seq-2-seq model from applies \n",
    "    * Maximum likelihood based training\n",
    "    * Optimize perplexity\n",
    "    * Results in poor quality when generating samples conditioned on new words not seen during training  \n",
    "    \n",
    "* Proposed MaskGAN  \n",
    "![image](image/mask-gan-output.png)\n",
    "    * Actor-critic GAN provides rewards at every time step\n",
    "    * Generate better samples \n",
    "    * Mode collapse problem is shown by reduced number of quadgrams\n",
    "    * Quality of the generated samples remain consistent despite mode collapse\n",
    "    * Authors claim mode collapse occure near the end of the sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Ensembles of Neocortical Microcircuits\n",
    "Blake Richards  \n",
    "\n",
    "* Deep learning has shown that learning hierarchical representation in the data is useful\n",
    "* Effective hierarchical learning depends on credit assignment which is the method of determining which neurons\n",
    "    and synapses in the hierarchy are ultimately responsible for behaviors. \n",
    "* Backpropagation does not align with how our brain works\n",
    "* Author proposed a computational model for hierarchical credit assignment inspired by neocortical microcircuits.   \n",
    "\n",
    "* Details of how neuron works in our brain\n",
    "![image](image/microcircuit.png)\n",
    "\n",
    "    * Pyramidal structure of neuron plays a key role\n",
    "    * Ensemble of pyramidal neurons\n",
    "    * Fully Connected Network\n",
    "    * Multiplex top-down and up-down signals from dendrites\n",
    "    \n",
    "* t-SNE on the representation of network of dendrites\n",
    "* Each unit is a group of neurons instead of one neuron\n",
    "    * Each burst may be related to burst of more than one neuron \n",
    "* Neurons that are derived from the same progenitor cells have similar connections and\n",
    "    are much more likely to be connedvted each other\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
